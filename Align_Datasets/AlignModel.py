# -*- coding: utf-8 -*-
"""
The align class
"""
import numpy as np
from photonpy import Dataset
import tensorflow as tf
import copy
import matplotlib.pyplot as plt
from photonpy import PostProcessMethods, Context


from Align_Modules.Affine import AffineModel
from Align_Modules.Polynomial3 import Polynomial3Model
from Align_Modules.RigidBody import RigidBodyModel
from Align_Modules.Splines import CatmullRomSpline2D
from Align_Modules.Shift import ShiftModel
from Align_Datasets.channel_class import channel
from Plot import Plot



#%% Align class
class AlignModel(Plot):
    '''
    The AlignModel Class is a class used for the optimization of a certain Dataset class. Important is 
    that the loaded class contains the next variables:
        ch1, ch2, ch2_original : Nx2 float32
            The two channels (and original channel2) that both contain positions callable by .pos
        coupled : bool
            True if the dataset is coupled (points are one-to-one)
        img, imgsize, mid: np.array
            The image borders, size and midpoint. Generated by self.imgparams            
    '''
    def __init__(self, developer_mode=False):
        ## Models
        self.AffineModel = None
        self.Polynomial3Model = None
        self.RigidBodyModel = None
        self.ShiftModel = None
        self.SplinesModel = None
        self.CP_locs = None
        self.gridsize=None
        self.edge_grids=None
        self.developer_mode=developer_mode
        
        ## Neighbours
        self.CP_idx_NN=None
        self.NN_maxDist=None
        self.NN_threshold=None
        self.NN_k=None
        self.Neighbours=False
        (self.NN1, self.NN2)=(None,None)
        
        Plot.__init__(self)
            
            
    def dev_mode(self, algorithm=None):
    # To check the parameters during simulation
        if self.developer_mode:
            #plt.close('all')
            _,_,fig,_=self.ErrorPlot(nbins=30)
            if algorithm is not None: fig.suptitle(algorithm, fontweight='bold', fontsize = 20)
            '''
            plt.pause(1)
            while True:
                if algorithm is not None: print('\nDeveloper Mode for', algorithm)    
                inp = input('Correct Parameters? [y/n]:')
                if inp == 'y':
                    continue
                elif inp == 'n':
                    sys.exit('Exit via developer mode')
                else:
                    print('Invalid input')
            plt.close('all')
            '''
                
        
    # common functions (also callabel via the Dataset classes)
    def imgparams(self):
    # calculate borders of system
    # returns a 2x2 matrix containing the edges of the image, a 2-vector containing
    # the size of the image and a 2-vector containing the middle of the image
        img = np.empty([2,2], dtype = float)
        img[0,0] = np.min(( np.min(self.ch1.pos[:,0]), np.min(self.ch2.pos[:,0]) ))
        img[1,0] = np.max(( np.max(self.ch1.pos[:,0]), np.max(self.ch2.pos[:,0]) ))
        img[0,1] = np.min(( np.min(self.ch1.pos[:,1]), np.min(self.ch2.pos[:,1]) ))
        img[1,1] = np.max(( np.max(self.ch1.pos[:,1]), np.max(self.ch2.pos[:,1]) ))
        return img, (img[1,:] - img[0,:]), (img[1,:] + img[0,:])/2
    
    
    def couple_dataset(self, FrameLinking=False):
    # couples dataset with a simple iterative nearest neighbour method
    # FrameLinking links the dataset per frame
        print('Coupling datasets with an iterative method...')
        (locsB,frameB)=([],[])
        for i in range(self.ch1.pos.shape[0]):
            if FrameLinking:
                sameframe_pos = self.ch2.pos[self.ch2.frame==self.ch1.frame[i],:]
                dists = np.sqrt(np.sum((self.ch1.pos[i,:]-sameframe_pos)**2,1))
            
                iB=np.argmin(dists)
                locsB.append(sameframe_pos[iB,:])
                frameB.append(self.ch1.frame[i])
            else:
                dists = np.sqrt(np.sum((self.ch1.pos[i,:]-self.ch2.pos)**2,1))
                iB=np.argmin(dists)
                locsB.append(self.ch2.pos[iB,:])
                frameB.append(self.ch2.frame[iB])
            
        if not locsB: raise ValueError('When Coupling Datasets, one of the Channels returns empty')
        
        self.ch2.pos = np.array(locsB)
        self.ch2.frame= np.array(frameB)
        self.coupled = True
        
        
    def Filter_Pairs(self, maxDist=150):
    # Filter pairs above maxDist
        print('Filtering pairs above',maxDist,'nm...')
        if not self.coupled: raise Exception('Dataset should be coupled before filtering pairs')
        dists = np.sqrt(np.sum( (self.ch1.pos - self.ch2.pos)**2 ,axis=1))
        idx = np.argwhere(dists<maxDist)
        if idx.shape[0]==0: raise ValueError('All localizations will be filtered out in current settings.')
        self.ch1.pos = np.squeeze(self.ch1.pos[idx,:],axis=1)
        self.ch2.pos = np.squeeze(self.ch2.pos[idx,:],axis=1)
        if self.ch2_original is not None: self.ch2_original.pos = np.squeeze(self.ch2_original.pos[idx,:],axis=1)
        self.dev_mode('Filter Pairs')
        
        
    def copy_models(self, other):
        self.AffineModel = copy.deepcopy(other.AffineModel)
        self.Polynomial3Model = copy.deepcopy(other.Polynomial3Model)
        self.RigidBodyModel = copy.deepcopy(other.RigidBodyModel)
        self.ShiftModel = copy.deepcopy(other.ShiftModel)
        self.SplinesModel = copy.deepcopy(other.SplinesModel)
        
        self.CP_locs = copy.deepcopy(other.CP_locs)
        self.gridsize = other.gridsize
        self.edge_grids = other.edge_grids
        if self.gridsize is not None:
            self.x1_min = other.x1_min
            self.x2_min = other.x2_min
            self.x1_max = other.x1_max
            self.x2_max = other.x2_max
        
        
    def reload_splines(self):
        if self.gridsize is not None:
            ch2_input = tf.Variable(self.ch2.pos / self.gridsize)
        
            self.SplinesModel.CP_idx = tf.cast(tf.stack(
                [( ch2_input[:,0]-self.x1_min+self.edge_grids)//1 ,
                 ( ch2_input[:,1]-self.x2_min+self.edge_grids)//1 ], axis=1), dtype=tf.int32)
            #self.SplinesModel.update_splines(self.CP_idx)
            
            
    #%% Split dataset or load subset
    def SubsetWindow(self, subset):
    # loading subset of dataset by creating a window of size subset 
        l_grid = self.mid - np.array([ subset*self.imgsize[0], subset*self.imgsize[1] ])/2
        r_grid = self.mid + np.array([ subset*self.imgsize[0], subset*self.imgsize[1] ])/2
        
        mask1 = np.where( (self.ch1.pos[:,0] >= l_grid[0]) * (self.ch1.pos[:,1] >= l_grid[1])
                            * (self.ch1.pos[:,0] <= r_grid[0]) * (self.ch1.pos[:,1] <= r_grid[1]) , True, False)
        mask2 = np.where( (self.ch2.pos[:,0] >= l_grid[0]) * (self.ch2.pos[:,1] >= l_grid[1])
                            * (self.ch2.pos[:,0] <= r_grid[0]) * (self.ch2.pos[:,1] <= r_grid[1]), True, False )

        self = self.gather(mask1, mask2)
        
        
    def SubsetRandom(self, subset):
    # loading subset of dataset by taking a random subset
        if self.coupled:
            mask1=np.random.choice(self.ch1.pos.shape[0], int(self.ch1.pos.shape[0]*subset))
            mask2=mask1
        else:
            mask1=np.random.choice(self.ch1.pos.shape[0], int(self.ch1.pos.shape[0]*subset))
            mask2=np.random.choice(self.ch2.pos.shape[0], int(self.ch2.pos.shape[0]*subset))
            
        self = self.gather(mask1, mask2)
        
        
    def SplitDataset(self):
    # Splits dataset into 2 halves for cross validation
        if self.Neighbours: print('WARNING: splitting datasets means the neighbours need to be reloaded!')
        N1=self.ch1.pos.shape[0]
        N2=self.ch2.pos.shape[0]
        if self.coupled:
            if N1!=N2: raise Exception('Datasets are coupled but not equal in size')
            mask1=np.ones(N1, dtype=bool)
            mask1[int(N1/2):]=False
            np.random.shuffle(mask1)  # create random mask to split dataset in two
            mask2 = np.abs(mask1-1).astype('bool')

            other1=self.gather(mask1, mask1)
            other2=self.gather(mask2, mask2)
            
        else:
            mask11=np.ones(N1, dtype=bool)
            mask11[int(N1/2):]=False
            mask12=np.ones(N2, dtype=bool)
            mask12[int(N2/2):]=False
            np.random.shuffle(mask11)  # create random mask to split dataset in two
            np.random.shuffle(mask12)
            mask21 = np.abs(mask11-1).astype('bool')
            mask22 = np.abs(mask12-1).astype('bool')
            
            other1=self.gather(mask11, mask12)
            other2=self.gather(mask21, mask22)
        
        return other1, other2
    
    
    def gather(self, idx1, idx2):
    # gathers the indexes of both channels
        other = copy.deepcopy(self)
        
        del other.ch1, other.ch2, other.ch2_original, 
        other.ch1 = channel(pos=self.ch1.pos[idx1,:], _xyI = self.ch1._xyI()[idx1,:], frame = self.ch1.frame[idx1])
        other.ch2 = channel(pos=self.ch2.pos[idx2,:], _xyI = self.ch2._xyI()[idx2,:], frame = self.ch2.frame[idx2])
        other.ch2_original = channel(pos=self.ch2_original.pos[idx2,:], _xyI = self.ch2_original._xyI()[idx2,:], frame = self.ch2.frame[idx2])
        return other
    
    
    #%% Generate Neighbours
    def find_neighbours(self, maxDistance=50, k=20):
    # Tries to generate neighbours according to brightest spots, and tries kNN otherwise
        print('Finding neighbours within a distance of',maxDistance,'nm for spots containing at least',k,'neighbours...')
        try:
            self.find_BrightNN(maxDistance=maxDistance, threshold=k)
        except Exception:
            print('Not enough bright Neighbours found in current setting. Switching to kNN with k = ',k,'!')
            self.find_kNN(k)
        
        
    def find_BrightNN(self, maxDistance = 50, threshold = 20):
    # generates the brightest neighbours
    # outputs a list of indices for the neigbhours
        with Context() as ctx: # loading all NN
            counts,indices = PostProcessMethods(ctx).FindNeighbors(self.ch1.pos, self.ch2.pos, maxDistance)
    
        ## putting all NNidx in a list 
        (idxlist, pos, i) = ([], 0,0)
        for count in counts:
            idxlist.append( np.stack([
                i * np.ones([count], dtype=int),
                indices[pos:pos+count] 
                ]) )
            pos+=count
            i+=1
            
        ## filtering the NNidx list to be square
        (idx1list, idx2list) = ([], [])
        for idx in idxlist:
            if idx.size>0 and idx.shape[1] > threshold: # filter for brightest spots above threshold
                # select random sample from brightest spost
                idx1list.append(idx[0, np.random.choice(idx.shape[1], threshold)]) 
                idx2list.append(idx[1, np.random.choice(idx.shape[1], threshold)]) 
    
        ## look if neighbours actually have been found
        if idx1list==[]: 
            raise Exception('No neighbours were generated. Adjust the threshold or maxDistance!')
        else:
            self.NN_maxDist=maxDistance
            self.NN_threshold=threshold
            
        ## Loading the indexes as matrices
        self.load_NN_matrix(idx1list, idx2list)
        
        
    def find_kNN(self, k):
    # generates the k-nearest neighbours
    # outputs a list of indices for the neigbhours
        (idx1list, idx2list) = ([],[])
        for i in range(self.ch1.pos.shape[0]):
            idx1list.append( (i * np.ones(k, dtype=int)) )
        for loc in self.ch1.pos:
            distances = np.sum((loc - self.ch2.pos)**2 , axis = 1)
            idx2list.append( np.argsort( distances )[:k] )
            
        self.NN_k=k
        
        ## Loading the indexes as matrices
        self.load_NN_matrix(idx1list, idx2list)
    
    
    def load_NN_matrix(self,idx1list, idx2list):
    # Takes the indexes for channel 1 and 2 and loads the matrix
        (NN1, NN2) = ([],[])
        for nn in idx1list: NN1.append(self.ch1.pos[nn, :])
        for nn in idx2list: NN2.append(self.ch2.pos[nn, :])
        
        self.NN1 = np.stack(NN1, axis=0)
        self.NN2 = np.stack(NN2, axis=0)
        self.Neighbours=True
        
    
    #%% Optimization functions
    #@tf.function
    def train_model(self, model, Nit, opt, ch1_tf=None, ch2_tf=None):
    # The training loop of the model
        if self.coupled:
            if ch1_tf is None: ch1_tf=tf.Variable(self.ch1.pos, dtype=tf.float32, trainable=False) 
            if ch2_tf is None: ch2_tf=tf.Variable(self.ch2.pos, dtype=tf.float32, trainable=False)
        elif self.Neighbours:
            if ch1_tf is None: ch1_tf=tf.Variable(self.NN1, dtype=tf.float32, trainable=False) 
            if ch2_tf is None: ch2_tf=tf.Variable(self.NN2, dtype=tf.float32, trainable=False)
        else:
            raise Exception('Dataset is not coupled but no Neighbours have been generated yet')
            
        
        for i in range(Nit):
            with tf.GradientTape() as tape:
                entropy = model(ch1_tf, ch2_tf)
            
            grads = tape.gradient(entropy, model.trainable_weights)
            opt.apply_gradients(zip(grads, model.trainable_weights))
        return model
            
    
    #%% Global Transforms (Affine, Polynomial3, RigidBody)
    ## Shift
    def Train_Shift(self, lr=1, Nit=200):
    # Training the RigidBody Mapping
        if self.ShiftModel is not None: raise Exception('Models can only be trained once')
        # initializing the model and optimizer
        self.ShiftModel=ShiftModel(direct=self.coupled)
        opt=tf.optimizers.Adagrad(lr)
        
        # Training the Model
        print('Training Shift Mapping (lr, #it) =',str((lr, Nit)),'...')
        self.ShiftModel = self.train_model(self.ShiftModel, Nit, opt)
        
    
    def Transform_Shift(self):
    # Transforms ch2 according to the Model
        print('Transforming Shift Mapping...')
        ch2_tf=tf.Variable(self.ch2.pos, dtype=tf.float32, trainable=False)
        ch2_tf=self.ShiftModel.transform_vec(ch2_tf)
        self.ch2.pos=np.array(ch2_tf.numpy())
        if np.isnan( self.ch2.pos ).any(): raise ValueError('ch2 contains infinities. The Shift mapping likely exploded.')
        self.dev_mode('Shift')
    
    
    ## RigidBody
    def Train_RigidBody(self, lr=1, Nit=200):
    # Training the RigidBody Mapping
        if self.AffineModel is not None: raise Exception('Models can only be trained once')
        if self.mid.all() != 0: print('WARNING! The image is not centered. This may have have detrimental effects for mapping a rotation!')
        # initializing the model and optimizer
        self.RigidBodyModel=RigidBodyModel(direct=self.coupled)
        opt=tf.optimizers.Adagrad(lr)
        
        # Training the Model
        print('Training RigidBody Mapping (lr, #it) =',str((lr, Nit)),'...')
        self.RigidBodyModel = self.train_model(self.RigidBodyModel, Nit, opt)
        
    
    def Transform_RigidBody(self):
    # Transforms ch2 according to the Model
        if self.mid.all() != 0: print('WARNING! The image is not centered. This may have have detrimental effects for mapping a rotation!')
        print('Transforming RigidBody Mapping...')
        ch2_tf=tf.Variable(self.ch2.pos, dtype=tf.float32, trainable=False)
        ch2_tf=self.RigidBodyModel.transform_vec(ch2_tf)
        self.ch2.pos=np.array(ch2_tf.numpy())
        if np.isnan( self.ch2.pos ).any(): raise ValueError('ch2 contains infinities. The RigidBody mapping likely exploded.')
        self.dev_mode('Rigid Body')
        
        
    ## Affine
    def Train_Affine(self, lr=1, Nit=200):
    # Training the Affine Mapping
        if self.AffineModel is not None: raise Exception('Models can only be trained once')
        if self.mid.all() != 0: print('WARNING! The image is not centered. This may have have detrimental effects for mapping a rotation!')
        # initializing the model and optimizer
        self.AffineModel=AffineModel(direct=self.coupled)
        
        # Training the Model
        print('Training Affine Mapping with (lr, #it) =',str((lr, Nit)),'...')
        # first train the A matrix (rot, shear, scaling)
        opt1=tf.optimizers.Adagrad(lr)
        self.AffineModel = self.train_model(self.AffineModel, Nit, opt1)
        
        # then train the d vector (shift)
        self.AffineModel.d._trainable=True
        self.AffineModel.A._trainable=False
        opt2=tf.optimizers.Adagrad(lr)
        self.AffineModel = self.train_model(self.AffineModel, Nit, opt2)
        
        
    
    def Transform_Affine(self):
    # Transforms ch2 according to the Model
        if self.mid.all() != 0: print('WARNING! The image is not centered. This may have have detrimental effects for mapping a rotation!')
        print('Transforming Affine Mapping...')
        ch2_tf=tf.Variable(self.ch2.pos, dtype=tf.float32, trainable=False)
        ch2_tf=self.AffineModel.transform_vec(ch2_tf)
        self.ch2.pos=np.array(ch2_tf.numpy())
        if np.isnan( self.ch2.pos ).any(): raise ValueError('ch2 contains infinities. The Affine mapping likely exploded.')
        self.dev_mode('Affine')
      
        
    ## Polynomial3
    def Train_Polynomial3(self, lr=1, Nit=200):
    # Training the Polynomial3 Mapping
        if self.Polynomial3Model is not None: raise Exception('Models can only be trained once')
        # initializing the model and optimizer
        self.Polynomial3Model=Polynomial3Model(direct=self.coupled)
        opt=tf.optimizers.Adagrad(lr)
        
        # Training the Model
        print('Training Polynomial3 Mapping (lr, #it)=',str((lr, Nit)),'...')
        self.Polynomial3Model = self.train_model(self.Polynomial3Model, Nit, opt)
        
    
    def Transform_Polynomial3(self):
    # Transforms ch2 according to the Model
        print('Transforming Polynomial3 Mapping...')
        ch2_tf=tf.Variable(self.ch2.pos, dtype=tf.float32, trainable=False)
        ch2_tf=self.Polynomial3Model.transform_vec(ch2_tf)
        self.ch2.pos=np.array(ch2_tf.numpy())
        if np.isnan( self.ch2.pos ).any(): raise ValueError('ch2 contains infinities. The Polynomial3 mapping likely exploded.')
        self.dev_mode('Polynomial-3')
        
        
    #%% CatmullRom Splines
    def Train_Splines(self, lr=1, Nit=200, gridsize=1000, edge_grids=1):
    # Training the Splines Mapping. lr is the learningrate, Nit the number of iterations
    # gridsize the size of the Spline grids and edge_grids the number of gridpoints extra at the edge
        if self.SplinesModel is not None: raise Exception('Models can only be trained once')
        
        ## Create variables normalized by gridsize
        ch2_input = tf.Variable( tf.stack([
            (self.ch2.pos[:,0] - np.min(self.ch2.pos[:,0]) ) / gridsize + edge_grids,
            (self.ch2.pos[:,1] - np.min(self.ch2.pos[:,1]) ) / gridsize + edge_grids
            ], axis=-1), dtype=tf.float32, trainable=False)
        ch1_input = tf.Variable( tf.stack([
            (self.ch1.pos[:,0] - np.min(self.ch2.pos[:,0]) ) / gridsize + edge_grids,
            (self.ch1.pos[:,1] - np.min(self.ch2.pos[:,1]) ) / gridsize + edge_grids
            ], axis=-1), dtype=tf.float32, trainable=False)
        
        self.edge_grids = edge_grids
        self.gridsize=gridsize
        
        self.x1_min=tf.reduce_min(tf.floor(ch2_input[:,1]))
        self.x2_min=tf.reduce_min(tf.floor(ch2_input[:,1]))
        self.x1_max=tf.reduce_max(tf.floor(ch2_input[:,0]))
        self.x2_max=tf.reduce_max(tf.floor(ch2_input[:,1]))
                
        ## Create grid
        x1_grid = tf.range(0, self.x1_max + self.edge_grids + 2)
        x2_grid = tf.range(0, self.x2_max + self.edge_grids + 2)
        self.ControlPoints = tf.stack(tf.meshgrid(x1_grid, x2_grid), axis=-1)
        
        ## Create Nearest Neighbours
        if not self.coupled:
            ch2_input = tf.Variable( tf.stack([
                (self.NN2[:,0,:] - np.min(self.ch2.pos[:,0]) ) / gridsize + edge_grids,
                (self.NN2[:,1,:] - np.min(self.ch2.pos[:,1]) ) / gridsize + edge_grids
                ], axis=-1), dtype=tf.float32, trainable=False)
            ch1_input = tf.Variable( tf.stack([
                (self.NN1[:,0,:] - np.min(self.ch2.pos[:,0]) ) / gridsize + edge_grids,
                (self.NN1[:,1,:] - np.min(self.ch2.pos[:,1]) ) / gridsize + edge_grids
                ], axis=-1), dtype=tf.float32, trainable=False)
            
        ## initialize optimizer
        opt=tf.optimizers.Adagrad(lr)
        self.SplinesModel=CatmullRomSpline2D(self.ControlPoints, direct=self.coupled)
        
        ## Training the Model
        print('Training Splines Mapping (lr, #it, gridsize) =',str((lr, Nit, gridsize)),'...') 
        self.SplinesModel = self.train_model(self.SplinesModel, Nit, opt, ch1_input, ch2_input)
        self.ControlPoints=self.SplinesModel.ControlPoints
                
    
    def Transform_Splines(self):
    # Transforms ch2 according to the Model
        print('Transforming Splines Mapping...')
        if self.gridsize is None: raise Exception('No Grid has been generated yet')
        
        ## Create variables normalized by gridsize
        ch2_input = tf.Variable( np.stack([
            (self.ch2.pos[:,0] - np.min(self.ch2.pos[:,0]) ) / self.gridsize + self.edge_grids,
            (self.ch2.pos[:,1] - np.min(self.ch2.pos[:,1]) ) / self.gridsize + self.edge_grids,      
            ], axis=-1), dtype=tf.float32, trainable=False)
            
        # transform the new ch2 model
        ch2_input=np.array( self.SplinesModel.transform_vec(ch2_input) * self.gridsize )
        self.ch2.pos=np.stack([
            ch2_input[:,0] + np.min(self.ch2.pos[:,0]) - self.edge_grids * self.gridsize,
            ch2_input[:,1] + np.min(self.ch2.pos[:,1]) - self.edge_grids * self.gridsize          
            ], axis=-1)
        
        # Error messages
        if np.isnan( self.ch2.pos ).any(): raise ValueError('ch2 contains infinities. The Splines mapping likely exploded.')
        self.dev_mode('Splines')
        
        
    ## Plotting the Grid
    def plot_SplineGrid(self, ch1=None, ch2=None, ch2_original=None, locs_markersize=10,
                        CP_markersize=8, d_grid=.1, grid_markersize=3, grid_opacity=1): 
        '''
        Plots the grid and the shape of the grid in between the Control Points
    
        Parameters
        ----------
        ch1 , ch2 , ch2_original : Nx2 tf.float32 tensor
            The tensor containing the localizations.
        d_grid : float, optional
            The precission of the grid we want to plot in between the
            ControlPoints. The default is .1.
        lines_per_CP : int, optional
            The number of lines we want to plot in between the grids. 
            Works best if even. The default is 1.
        locs_markersize : float, optional
            The size of the markers of the localizations. The default is 10.
        CP_markersize : float, optional
            The size of the markers of the Controlpoints. The default is 8.
        grid_markersize : float, optional
            The size of the markers of the grid. The default is 3.
        grid_opacity : float, optional
            The opacity of the grid. The default is 1.
    
        Returns
        -------
        None.
    
        '''
        print('Plotting the Spline Grid...')
        if ch1 is None:
            ch1=self.ch1.pos
            ch2=self.ch2.pos
            ch2_original=self.ch2_original.pos
        
        ## The original points
        ch1 = tf.Variable( tf.stack([
            (ch1[:,0] - np.min(ch2_original[:,0]) ) + self.edge_grids*self.gridsize,
            (ch1[:,1] - np.min(ch2_original[:,1])) + self.edge_grids*self.gridsize
            ], axis=-1), dtype=tf.float32, trainable=False)
        ch2 = tf.Variable( tf.stack([
            (ch2[:,0] - np.min(ch2_original[:,0]) ) + self.edge_grids*self.gridsize,
            (ch2[:,1] - np.min(ch2_original[:,1]) ) + self.edge_grids*self.gridsize
            ], axis=-1), dtype=tf.float32, trainable=False)
        ch2_original = tf.Variable( tf.stack([
            (ch2_original[:,0] - np.min(ch2_original[:,0]) ) + self.edge_grids*self.gridsize,
            (ch2_original[:,1] - np.min(ch2_original[:,1]) ) + self.edge_grids*self.gridsize
            ], axis=-1), dtype=tf.float32, trainable=False)
        
        # plotting the localizations
        plt.figure()
        plt.scatter(ch2[:,0],ch2[:,1], c='red', marker='.', s=locs_markersize, label='Mapped CH2')
        plt.scatter(ch2_original[:,0],ch2_original[:,1], c='orange', marker='.', 
                    alpha=.7, s=locs_markersize-2, label='Original CH2')
        plt.scatter(ch1[:,0],ch1[:,1], c='green', marker='.', s=locs_markersize, label='Original CH1')
               
        
        ## Horizontal Grid
        x1_grid = tf.range(0, self.x1_max + self.edge_grids + 2, delta=d_grid)
        x2_grid = tf.range(0, self.x2_max + self.edge_grids + 2, delta=d_grid*2)
        GridH = tf.reshape(tf.stack(tf.meshgrid(x1_grid, x2_grid), axis=-1) , (-1,2))       
        
        ## Vertical Grid
        x1_grid = tf.range(0, self.x1_max + self.edge_grids + 2, delta=d_grid*2)
        x2_grid = tf.range(0, self.x2_max + self.edge_grids + 2, delta=d_grid)
        GridV = tf.reshape(tf.stack(tf.meshgrid(x1_grid, x2_grid), axis=-1), (-1,2))
        
        Grid = self.SplinesModel.transform_vec(tf.concat([GridH,GridV], axis=0) ) * self.gridsize
        plt.scatter(Grid[:,0], Grid[:,1], c='c', marker='.', s=grid_markersize, alpha=grid_opacity)
        
        
        ## Controlpoints Grid
        x1_grid = tf.range(0, self.x1_max + self.edge_grids + 2, delta=d_grid)
        x2_grid = tf.range(0, self.x2_max + self.edge_grids + 2)
        GridH = tf.reshape(tf.stack(tf.meshgrid(x1_grid, x2_grid), axis=-1) , (-1,2))       
        
        ## Vertical Grid
        x1_grid = tf.range(0, self.x1_max + self.edge_grids + 2)
        x2_grid = tf.range(0, self.x2_max + self.edge_grids + 2, delta=d_grid)
        GridV = tf.reshape(tf.stack(tf.meshgrid(x1_grid, x2_grid), axis=-1), (-1,2))
        
        Grid = self.SplinesModel.transform_vec(tf.concat([GridH,GridV], axis=0) ) * self.gridsize
        plt.scatter(Grid[:,0], Grid[:,1], c='b', marker='.', s=grid_markersize, alpha=grid_opacity)
        
        # plotting the ControlPoints
        plt.scatter(self.ControlPoints[:,:,0]*self.gridsize, self.ControlPoints[:,:,1]*self.gridsize,
                    c='b', marker='o', s=CP_markersize, label='ControlPoints')
        
        plt.legend()
        plt.tight_layout()